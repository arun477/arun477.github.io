<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Arun Arumugam on Arun</title><link>https://arun477.github.io/</link><description>Recent content in Arun Arumugam on Arun</description><generator>Hugo -- 0.145.0</generator><language>en</language><lastBuildDate>Sat, 07 Jun 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://arun477.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Jupyter to LLM Extractor</title><link>https://arun477.github.io/utilities/jupyter_extractor/</link><pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><guid>https://arun477.github.io/utilities/jupyter_extractor/</guid><description>A Chrome extension that extracts content from Jupyter notebooks for more effective interactions with large language models</description></item><item><title>llmdirtree: Directory Visualization and Context Generator for LLM Workflows</title><link>https://arun477.github.io/utilities/directory-tree-generator/</link><pubDate>Sat, 15 Mar 2025 00:00:00 +0000</pubDate><guid>https://arun477.github.io/utilities/directory-tree-generator/</guid><description>A Python CLI tool that generates both directory trees and code context summaries optimized for LLM interactions</description></item><item><title>Beifong: AI-Powered Content Curation and Podcast Generation</title><link>https://arun477.github.io/posts/beifong_podcast_generator/</link><pubDate>Sat, 07 Jun 2025 00:00:00 +0000</pubDate><guid>https://arun477.github.io/posts/beifong_podcast_generator/</guid><description>&lt;h2 id="what-it-does">What It Does&lt;/h2>
&lt;p>&lt;strong>Beifong&lt;/strong> is an AI content curation platform that monitors your feeds, analyzes content, and generates podcasts from the stuff you actually care about. Named after Toph Beifong.&lt;/p>
&lt;p>It handles RSS feeds, social media scraping, content analysis, and converts everything into audio content. Basically automates the process of finding good content and turning it into podcasts.&lt;/p>
&lt;div class="custom-html-container " id="">
&lt;div style="position: relative; width: 100%; height: 0; padding-top: 56.2500%;
padding-bottom: 0; box-shadow: 0 2px 8px 0 rgba(63,69,81,0.16); margin-top: 1.6em; margin-bottom: 0.9em; overflow: hidden;
border-radius: 8px; will-change: transform;">
&lt;iframe loading="lazy" style="position: absolute; width: 100%; height: 100%; top: 0; left: 0; border: none; padding: 0;margin: 0;"
src="https://www.canva.com/design/DAGoUfv8ICM/L34r-foQtTps02XXeUOUYA/watch?embed" allowfullscreen="allowfullscreen" allow="fullscreen">
&lt;/iframe>
&lt;/div>
&lt;/div>
&lt;script>
document.addEventListener('DOMContentLoaded', function() {
const container = document.getElementById('');
if (container) {
const scripts = container.getElementsByTagName('script');
for (let i = 0; i &lt; scripts.length; i++) {
const script = document.createElement('script');
if (scripts[i].src) {
script.src = scripts[i].src;
} else {
script.textContent = scripts[i].textContent;
}
document.body.appendChild(script);
}
}
});
&lt;/script>
&lt;p>&lt;strong>Demo:&lt;/strong> &lt;a href="https://www.youtube.com/watch?v=dB8FZY3x9EY">Watch on YouTube&lt;/a>&lt;/p></description></item><item><title>Mel Spectrogram</title><link>https://arun477.github.io/posts/mel_spectrogram/</link><pubDate>Sun, 23 Mar 2025 00:00:00 +0000</pubDate><guid>https://arun477.github.io/posts/mel_spectrogram/</guid><description>&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>Mel spectrogram is an audio analyzing technique which is predominantly applied to raw audio form as a preprocessing step before passing to any model for predictions. For example, speech-to-text models&amp;rsquo; input raw audio is converted into mel spectrogram before passing to the model.&lt;/p>
&lt;p>In general, mel spectrogram is a kind of visualization technique which takes into account how the human ear perceives audio frequencies during this low dimensional conversion process. Compared to the raw audio waveform and the more natural way humans perceive audio, these are all the predominant reasons we prefer audio in mel spectrogram form.&lt;/p></description></item><item><title>Bharat-NanoBEIR: Indian Language Information Retrieval Dataset</title><link>https://arun477.github.io/posts/embedding_eval_for_indic/</link><pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><guid>https://arun477.github.io/posts/embedding_eval_for_indic/</guid><description>&lt;p>The &lt;strong>Bharat-NanoBEIR&lt;/strong> dataset is part of a collection that provides information retrieval datasets for Indian languages. It is derived from the NanoBEIR project, which offers smaller versions of BEIR datasets with 50 queries and up to 10K documents each.&lt;/p>
&lt;h3 id="dataset-overview">Dataset Overview&lt;/h3>
&lt;ul>
&lt;li>&lt;strong>Queries:&lt;/strong> 50 per dataset&lt;/li>
&lt;li>&lt;strong>Documents:&lt;/strong> Up to 10K per dataset&lt;/li>
&lt;/ul>
&lt;p>This dataset aims to facilitate research and development in the field of information retrieval, particularly for Indian languages.&lt;/p>
&lt;h3 id="learn-more">Learn More&lt;/h3>
&lt;p>For further details and to explore the dataset, please visit the following link:&lt;/p></description></item></channel></rss>